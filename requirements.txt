# MoE Compression Requirements
# Base environment should have: transformers, torch, accelerate, deepspeed, datasets

# Additional dependencies
hydra-core>=1.3.0
omegaconf>=2.3.0
wandb>=0.15.0
bitsandbytes>=0.41.0  # For model quantization
sentencepiece>=0.1.99  # For tokenization
lm-eval>=0.4.0  # For evaluation
scipy>=1.10.0  # For optimization
tqdm>=4.65.0

# Optional but recommended
flash-attn>=2.0.0  # For faster attention (if compatible with your CUDA version)
