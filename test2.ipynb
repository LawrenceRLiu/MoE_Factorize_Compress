{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f66fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import tqdm\n",
    "from typing import List, Tuple, Optional, Union\n",
    "from src.utils.blockwise_diag_matricies import BlockwiseDiagMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62a2b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralBlockwiseDiagMatrix(nn.Module):\n",
    "    def __init__(self, n_experts:int, \n",
    "                 d_1:int,\n",
    "                 d_2:int,\n",
    "                 k:int,\n",
    "                 eps:float= 1e-4\n",
    "                 ):\n",
    "        super(GeneralBlockwiseDiagMatrix, self).__init__()\n",
    "        #generalized blockwise diagonal matrix with n_experts different matrices of shape (d_1, d_2) each composed of k blocks\n",
    "        assert d_1 % k == 0, \"d_1 must be divisible by k\"\n",
    "        assert d_2 % k == 0, \"d_2 must be divisible by k\"\n",
    "        \n",
    "        self.k = k\n",
    "        self.d_1 = d_1\n",
    "        self.d_2 = d_2\n",
    "        self.n_experts = n_experts\n",
    "        \n",
    "        self.X = nn.Parameter(torch.randn(n_experts, k, d_1 // k, d_2 // k)*eps)\n",
    "        print(f\"block size: {d_1 // k} x {d_2 // k}\")\n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        #just a simple forward pass that goes over all the experts, will need to rewritten later to handle routing\n",
    "        # x is of shape (...., n_experts, d_2)\n",
    "        # of of (..., d_1)\n",
    "        assert x.shape[-1] == self.d_2, f\"input has incompatible shape {x.shape}, expected shape (..., {self.n_experts}, {self.d_2})\"\n",
    "        \n",
    "        if x.shape[-2] == self.n_experts:\n",
    "            out = torch.einsum(\n",
    "                \"ekij, ...ekj -> ...eki\",\n",
    "                self.X,\n",
    "                x.view(*x.shape[:-2], self.n_experts, self.k, self.d_2 // self.k)\n",
    "            ) #shape of (..., n_experts, k, d_2//k)\n",
    "            return out.contiguous().view(*x.shape[:-2], self.n_experts, self.d_1)\n",
    "        else:\n",
    "            assert x.shape[-2] == 1, f\"input has incompatible shape {x.shape}, expected shape (..., {self.n_experts}, {self.d_2}) or (..., 1, {self.d_2})\"\n",
    "            out = torch.einsum(\n",
    "                \"ekij, ...kj -> ...eki\",\n",
    "                self.X,\n",
    "                x.view(*x.shape[:-2], self.k, self.d_2 // self.k)\n",
    "            ) #shape of (..., n_experts, k, d_2//k)\n",
    "            return out.contiguous().view(*x.shape[:-2], self.n_experts, self.d_1)\n",
    "    \n",
    "    #multiply with the core matrix\n",
    "    def __matmul__(self, core: torch.Tensor) -> torch.Tensor:\n",
    "        #expert core to be a matrix of shape (d_2, n)\n",
    "        #or of shape (n_experts, d_2, n)\n",
    "        assert core.shape[-2] == self.d_2, f\"core matrix has incompatible shape {core.shape}, expected shape (*, {self.d_1}, n)\"\n",
    "        \n",
    "        if core.dim() == 2:\n",
    "            out = torch.einsum(\n",
    "                \"ekij,kjl->ekil\",\n",
    "                self.X,\n",
    "                core.view(self.k, self.d_2 // self.k, -1)\n",
    "            ) #shape of (n_experts, k, d_1//k, n)\n",
    "            return out.contiguous().view(self.n_experts, self.d_1, -1)\n",
    "        elif core.dim() == 3:\n",
    "            assert core.shape[0] == self.n_experts, f\"core matrix has incompatible shape {core.shape}, expected shape ({self.n_experts}, {self.d_2}, n)\"\n",
    "            out = torch.einsum(\n",
    "                \"ekij,ekjl->ekil\",\n",
    "                self.X,\n",
    "                core.view(self.n_experts, self.k, self.d_2 // self.k,\n",
    "                            -1)\n",
    "            ) #shape of (n_experts, k, d_1//k, n)\n",
    "            return out.contiguous().view(self.n_experts, self.d_1, -1)\n",
    "        else:\n",
    "            raise ValueError(f\"core matrix has incompatible shape {core.shape}, expected shape (*, {self.d_2}, n)\")\n",
    "        \n",
    "    def __rmatmul__(self, core: torch.Tensor) -> torch.Tensor:\n",
    "        #expert core to be a matrix of shape (n, d_1)\n",
    "        #or of shape (n_experts, n, d_1)\n",
    "        assert core.shape[-1] == self.d_1, f\"core matrix has incompatible shape {core.shape}, expected shape (n, {self.d_1})\"\n",
    "        \n",
    "        if core.dim() == 2:\n",
    "            out = torch.einsum(\n",
    "                \"lki,ekij->elkj\",\n",
    "                core.view(-1, self.k, self.d_1 // self.k),\n",
    "                self.X\n",
    "            ) #shape of (n_experts, n, k, d_2//k)\n",
    "            return out.contiguous().view(self.n_experts, -1, self.d_2)\n",
    "        elif core.dim() == 3:\n",
    "            assert core.shape[0] == self.n_experts, f\"core matrix has incompatible shape {core.shape}, expected shape ({self.n_experts}, n, {self.d_1})\"\n",
    "            out = torch.einsum(\n",
    "                \"elki,ekij->elkj\",\n",
    "                core.view(self.n_experts, -1, self.k, self.d_1 // self.k),\n",
    "                self.X\n",
    "            ) #shape of (n_experts, n, k, d_2//k)\n",
    "            return out.contiguous().view(self.n_experts, -1, self.d_2)\n",
    "        \n",
    "    def to_dense(self) -> torch.Tensor:\n",
    "        #return the dense representation of the blockwise diagonal matrix\n",
    "        dense_matrices = []\n",
    "        for i in range(self.n_experts):\n",
    "            blocks = [self.X[i, j] for j in range(self.k)]\n",
    "            dense_matrix = torch.block_diag(*blocks)\n",
    "            dense_matrices.append(dense_matrix)\n",
    "        return torch.stack(dense_matrices, dim=0)\n",
    "    \n",
    "    @property\n",
    "    def params_per_expert(self) -> int:\n",
    "        return self.X[0].numel()\n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a9c6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper(nn.Module):\n",
    "    def __init__(self, n_experts:int,\n",
    "                 d_out:int,\n",
    "                 d_in:int,\n",
    "                 k:Union[int, Tuple[int]],\n",
    "                 d_inner:int = -1,\n",
    "                 eps:float=1e-4):\n",
    "        \n",
    "        super(Wrapper, self).__init__()\n",
    "        \n",
    "        if isinstance(k, int):\n",
    "            k = (k, k)\n",
    "        \n",
    "        #if d_inner is not given, set it to the minimum of d_in and d_out\n",
    "        if d_inner == -1:\n",
    "            d_inner = min(d_in, d_out)\n",
    "        self.d_inner = d_inner\n",
    "        \n",
    "        self.B1 = GeneralBlockwiseDiagMatrix(n_experts, d_out, d_inner, k[0], \n",
    "                                             eps=eps)\n",
    "        self.B2 = GeneralBlockwiseDiagMatrix(n_experts, d_inner, d_in, k[1], \n",
    "                                             eps=eps)\n",
    "        \n",
    "        monarch_permutation = torch.arange(d_inner).view(-1, self.B1.X.shape[-1]).T.flatten()\n",
    "        # print(\"monarch_permutation:\", monarch_permutation)\n",
    "        self.permutation_matricies = nn.Buffer(\n",
    "            torch.stack([monarch_permutation for _ in range(n_experts)], dim=0)\n",
    "        ) #shape of (n_experts, d_inner)\n",
    "        self.inverse_permutation_matricies = nn.Buffer(\n",
    "            torch.argsort(self.permutation_matricies, dim=1)\n",
    "        ) #shape of (n_experts, d_inner)\n",
    "        self.perm_idxs = nn.Buffer(\n",
    "            torch.arange(n_experts).unsqueeze(-1)\n",
    "        )\n",
    "        #we expect this to be the permutation of x when applied to the right, ie \n",
    "        # P @ x = x[P]\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        #same logic as the wrapper multiplication\n",
    "        out = self.B2(x)  #shape of (..., n_experts, d_inner)\n",
    "        out = out[..., self.perm_idxs, self.permutation_matricies]  #permute along d_inner\n",
    "        out = self.B1(out)  #shape of (..., n_experts, d_out)\n",
    "        return out\n",
    "    \n",
    "    def __matmul__(self, core: torch.Tensor) -> torch.Tensor:\n",
    "        #wrapper @ core \n",
    "        #multiply core with B2, then permute, then multiply with B1\n",
    "        # print(\"core shape:\", core.shape)\n",
    "        out = self.B2 @ core  #shape of (n_experts, d_inner, n)\n",
    "        out = out[self.perm_idxs, self.permutation_matricies, :]  #permute along d_inner\n",
    "        out = self.B1 @ out  #shape of (n_experts, d_out, n)\n",
    "        return out\n",
    "    \n",
    "    def __rmatmul__(self, core: torch.Tensor) -> torch.Tensor:\n",
    "        #core @ wrapper \n",
    "        #multiply core with B1, then permute, then multiply with B2\n",
    "        out = core @ self.B1  #shape of (n_experts, n, d_inner)\n",
    "        assert out.shape == (self.B1.n_experts, core.shape[1], self.d_inner), \\\n",
    "            f\"Intermediate shape mismatch: got {out.shape}, expected {(self.B1.n_experts, core.shape[1], self.d_inner)}\"\n",
    "        # print(\"out.shape after B1:\", out.shape)\n",
    "        # print(\"self.perm_idxs shape:\", self.perm_idxs.shape)\n",
    "        # print(\"self.inverse_permutation_matricies shape:\", self.inverse_permutation_matricies.shape)\n",
    "        # print(\"self.permutation_matricies:\", self.permutation_matricies.shape)\n",
    "        out = out[self.perm_idxs, :, self.inverse_permutation_matricies]  #permute along d_inner\n",
    "        out = out.transpose(1,2)\n",
    "        # print(\"out.shape after permute:\", out.shape)\n",
    "        out = out @ self.B2  #shape of (n_experts, n, d_in)\n",
    "        return out\n",
    "    \n",
    "    @property\n",
    "    def params_per_expert(self) -> int:\n",
    "        return self.B1.params_per_expert + self.B2.params_per_expert\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd6f402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64, 768])\n"
     ]
    }
   ],
   "source": [
    "d_1,d_2,d_3 = 128, 768, 64\n",
    "\n",
    "\n",
    "a = torch.randn(d_1, d_2, d_3)\n",
    "\n",
    "idxs = torch.stack([torch.randperm(d_3) for _ in range(d_1)], dim=0)\n",
    "a_permuted = a[torch.arange(d_1).unsqueeze(-1), :, idxs]\n",
    "print(a_permuted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f8b12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found n weights: 128\n"
     ]
    }
   ],
   "source": [
    "model = \"Qwen/Qwen3-30B-A3B-Base\"\n",
    "layer = 0\n",
    "proj = \"gate_proj\"\n",
    "device = torch.device(\"cuda:7\")\n",
    "weights_paths = glob.glob(f\"../LLM_data/{model}/original_weights/layer_{layer}/mlp.expert_*.{proj}.pt\")\n",
    "print(\"Found n weights:\", len(weights_paths))\n",
    "weights = [torch.load(path, map_location=device)[\"weight\"].to(torch.float32).detach() for path in weights_paths]\n",
    "\n",
    "hessian_path = \"hessian_diag/SlimPajama-627B/n_samples_512_ctx_len_8192/seed_0\"\n",
    "hessian_diags = [\n",
    "    torch.load(w.replace(\"original_weights\", hessian_path), map_location=device)[\"hessianDiag\"].to(torch.float32) for w in weights_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0df2d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompressedProj(nn.Module):\n",
    "    def __init__(self, weights:list[torch.Tensor], hessian_diags:list[torch.Tensor],\n",
    "                 k:Union[int, Union[int, Tuple[int]]]=16, \n",
    "                 d_core:int=-1, #not used currently\n",
    "                 d_wrapper_inner:Union[int, Tuple[int]]=-1,\n",
    "                 device:torch.device=torch.device(\"cpu\"),\n",
    "                 eps:float=1e-4):\n",
    "        super().__init__()\n",
    "        self.original_weights = nn.Buffer(torch.stack(weights))  # (n_experts, out_dim, in_dim)\n",
    "        self.hessian_diags = nn.Buffer(torch.stack(hessian_diags))  # (n_experts, in_dim)\n",
    "        \n",
    "        #calculate the loss scaling just to make sure that the losses are readable\n",
    "        self.loss_scaling = torch.sum(self.original_weights**2 * self.hessian_diags.unsqueeze(1),\n",
    "                                      dim=(1,2), keepdim=True)  #shape (n_experts, 1, 1)\n",
    "        \n",
    "        if d_core == -1:\n",
    "            d_core = min(self.original_weights.shape[1], self.original_weights.shape[2])\n",
    "        if isinstance(k, int):\n",
    "            k = (k, k)\n",
    "        if isinstance(d_wrapper_inner, int):\n",
    "            d_wrapper_inner = (d_wrapper_inner, d_wrapper_inner)\n",
    "            \n",
    "        self.wrapper_A = Wrapper(\n",
    "            n_experts=self.original_weights.shape[0],\n",
    "            d_out=self.original_weights.shape[1],\n",
    "            d_in=d_core,\n",
    "            k=k[0],\n",
    "            d_inner=d_wrapper_inner[0],\n",
    "            eps = eps\n",
    "        )\n",
    "        self.wrapper_B = Wrapper(\n",
    "            n_experts=self.original_weights.shape[0],\n",
    "            d_out=d_core,\n",
    "            d_in=self.original_weights.shape[2],\n",
    "            k=k[1],\n",
    "            d_inner=d_wrapper_inner[1],\n",
    "            eps = eps   \n",
    "        )\n",
    "        \n",
    "        self.d_core = d_core\n",
    "        self.core_weight = nn.Parameter(torch.zeros(d_core, d_core)*eps)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.wrapper_B(x) #shape of (..., n_experts, d_core)\n",
    "        out = F.linear(out.view(-1, self.d_core), self.core_weight).view(*x.shape[:-2], \n",
    "                                                                         self.n_experts, self.d_core)\n",
    "        \n",
    "        out = self.wrapper_A(out)  #shape of (..., n_experts, d_out)\n",
    "        return out\n",
    "    \n",
    "    @property\n",
    "    def n_experts(self)->int:\n",
    "        return self.original_weights.shape[0]\n",
    "    \n",
    "    def reconstruct_weight(self)->torch.Tensor:\n",
    "        return self.wrapper_A @ (self.core_weight @ self.wrapper_B)  # (n_experts, out_dim, in_dim)\n",
    "    \n",
    "    def recon_loss(self)->torch.Tensor:\n",
    "        W_recon = self.reconstruct_weight()\n",
    "        # print(\"W_recon:\", W_recon)\n",
    "        # raise NotImplementedError(\"Debugging print statement added.\")\n",
    "        assert W_recon.shape == self.original_weights.shape, \\\n",
    "            f\"Reconstructed weight shape {W_recon.shape} does not match original weight shape {self.original_weights.shape}\"\n",
    "        # print(self.original_weights)\n",
    "        loss = (W_recon - self.original_weights)**2 * self.hessian_diags.unsqueeze(1) #shape (n_experts, out_dim, in_dim)\n",
    "        #multiply by hessian diag\n",
    "        # print(\"loss shape:\", loss.shape)\n",
    "        # print(\"loss scaling shape:\", self.loss_scaling.shape)\n",
    "        return torch.sum(loss/self.loss_scaling)/self.n_experts\n",
    "    \n",
    "    def get_new_params(self)->int:\n",
    "        n_params = 0\n",
    "        n_params += self.core_weight.numel()\n",
    "        count_wrapper_params = lambda x: sum(p.numel() for p in x.parameters())\n",
    "        \n",
    "        n_params += count_wrapper_params(self.wrapper_A)\n",
    "        n_params += count_wrapper_params(self.wrapper_B)\n",
    "        return n_params\n",
    "    \n",
    "    def get_original_params(self)->int:\n",
    "        return self.original_weights.numel()\n",
    "    \n",
    "    def get_sparsity_factor(self)->float:\n",
    "        return self.get_new_params()/self.get_original_params()\n",
    "    \n",
    "    @property\n",
    "    def params_per_expert(self) -> int:\n",
    "        return self.core_weight.numel() + self.wrapper_A.params_per_expert + self.wrapper_B.params_per_expert\n",
    "        \n",
    "    @property\n",
    "    def original_params_per_expert(self) -> int:\n",
    "        return self.original_weights[0].numel()  \n",
    "    \n",
    "    def get_active_sparsity_factor(self) -> float:\n",
    "        print(\"params per expert:\", self.params_per_expert)\n",
    "        print(\"original params per expert:\", self.original_params_per_expert)\n",
    "        return self.params_per_expert / self.original_params_per_expert\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e804e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block size: 96 x 96\n",
      "block size: 96 x 96\n",
      "block size: 96 x 96\n",
      "block size: 96 x 256\n",
      "sparsity factor: 0.2685546875\n",
      "params per expert: 1007616\n",
      "original params per expert: 1572864\n",
      "active sparsity factor: 0.640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [01:24<00:00, 11.89it/s, loss=0.2, lr=0.001] \n"
     ]
    }
   ],
   "source": [
    "test_module = CompressedProj(weights, hessian_diags, device=device, eps=1e-1,\n",
    "                             k=8,\n",
    "                             d_wrapper_inner=-1\n",
    "                             ).to(device)\n",
    "print(\"sparsity factor:\", test_module.get_sparsity_factor())\n",
    "print(\"active sparsity factor:\", test_module.get_active_sparsity_factor())\n",
    "\n",
    "optimizer = torch.optim.Adam(test_module.parameters(), lr=1e-3)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(test_module.parameters(), lr=1e-3,\n",
    "#                               weight_decay=1e-1)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50,\n",
    "                                                    #    threshold=1e-2)\n",
    "\n",
    "losses = []\n",
    "bar = tqdm.tqdm(range(1000), desc=\"Training\")\n",
    "for step in bar:\n",
    "    optimizer.zero_grad()\n",
    "    loss = test_module.recon_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # scheduler.step(loss)\n",
    "    bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c48adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.5951e-03, -8.9177e-03,  9.5120e-03,  ...,  1.4247e-03,\n",
      "          -1.1199e-02,  1.0148e-03],\n",
      "         [ 7.8070e-03,  7.7315e-03, -1.1488e-02,  ...,  4.9858e-03,\n",
      "          -5.7451e-03,  3.0388e-03],\n",
      "         [ 8.2818e-03,  1.6137e-02,  3.1763e-03,  ...,  9.0442e-03,\n",
      "           1.1111e-02,  3.3685e-03],\n",
      "         ...,\n",
      "         [-8.2251e-03, -4.7714e-03,  6.4409e-03,  ...,  1.1810e-02,\n",
      "          -2.9683e-03, -1.8324e-02],\n",
      "         [ 1.0254e-02,  7.4702e-03,  5.3836e-03,  ..., -1.3621e-02,\n",
      "          -2.0328e-02,  9.4408e-03],\n",
      "         [-1.1478e-02, -6.8769e-03, -4.6139e-03,  ...,  3.6450e-03,\n",
      "           2.0510e-03,  8.8717e-03]],\n",
      "\n",
      "        [[ 9.3432e-03, -3.5120e-02,  2.8383e-02,  ..., -4.9740e-02,\n",
      "           4.5557e-03,  3.4468e-03],\n",
      "         [ 7.1570e-03, -1.9476e-02,  1.0245e-02,  ...,  8.3801e-03,\n",
      "          -1.0147e-02,  8.2873e-04],\n",
      "         [-3.4481e-03,  2.5425e-02,  8.7634e-03,  ..., -1.6035e-02,\n",
      "           3.1144e-02, -2.2695e-02],\n",
      "         ...,\n",
      "         [-2.7744e-02, -1.7766e-02, -2.7326e-02,  ..., -1.7231e-02,\n",
      "           2.7179e-02, -2.1541e-02],\n",
      "         [-2.3575e-02, -6.2684e-02,  1.8742e-02,  ..., -2.2021e-02,\n",
      "           1.7753e-02, -8.0116e-05],\n",
      "         [ 1.2293e-02, -4.5990e-03,  1.9411e-02,  ...,  4.8991e-03,\n",
      "          -7.5731e-03, -2.8449e-02]],\n",
      "\n",
      "        [[-9.5174e-03,  9.8241e-03,  3.8419e-03,  ...,  9.2611e-04,\n",
      "          -1.6467e-02,  3.5274e-04],\n",
      "         [-1.0335e-02,  2.8943e-02,  2.0033e-02,  ..., -3.2005e-03,\n",
      "          -2.4888e-03,  1.6048e-03],\n",
      "         [-4.4796e-03,  1.6704e-02,  7.9558e-03,  ..., -2.4154e-02,\n",
      "           2.4524e-02, -4.2744e-03],\n",
      "         ...,\n",
      "         [ 3.4913e-05, -9.9355e-05,  2.4943e-04,  ...,  4.4391e-05,\n",
      "           7.9274e-05,  7.8608e-06],\n",
      "         [-1.8088e-02, -5.8487e-03,  1.1143e-02,  ..., -1.7282e-02,\n",
      "          -1.3342e-02,  3.2695e-03],\n",
      "         [-2.1026e-03, -2.1741e-02,  1.6317e-03,  ..., -2.8133e-02,\n",
      "           4.6348e-03,  1.5539e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1332e-02,  7.8597e-03,  6.8490e-03,  ..., -2.6811e-03,\n",
      "           1.1443e-02,  4.5007e-03],\n",
      "         [ 7.8557e-03, -3.7897e-03, -1.0549e-02,  ..., -3.9656e-03,\n",
      "           3.2927e-03,  9.9735e-03],\n",
      "         [-2.5423e-02,  5.8506e-03, -1.8435e-03,  ..., -5.0182e-03,\n",
      "           6.3704e-03, -1.7866e-03],\n",
      "         ...,\n",
      "         [-2.4547e-03,  2.1228e-02,  9.8293e-03,  ..., -1.0963e-02,\n",
      "          -2.0349e-02,  7.2839e-03],\n",
      "         [ 1.3771e-02, -6.8512e-04,  6.9120e-03,  ...,  1.4961e-02,\n",
      "          -1.1138e-03,  1.4713e-02],\n",
      "         [ 9.4327e-05,  1.9651e-02, -1.3492e-03,  ...,  1.4192e-02,\n",
      "           1.5409e-02, -2.1907e-02]],\n",
      "\n",
      "        [[-4.1705e-03,  7.1565e-03, -5.1842e-03,  ..., -1.1533e-03,\n",
      "           8.8004e-03, -4.6657e-03],\n",
      "         [ 1.3276e-03,  2.6505e-02,  8.6712e-03,  ...,  6.9537e-03,\n",
      "          -5.2126e-04, -1.7485e-02],\n",
      "         [ 9.8658e-04,  2.9381e-04, -1.0057e-03,  ..., -2.2411e-02,\n",
      "          -8.1645e-03, -7.0547e-03],\n",
      "         ...,\n",
      "         [-2.3666e-03, -3.3234e-03,  6.1041e-03,  ..., -2.8577e-02,\n",
      "           2.8862e-03, -5.5114e-03],\n",
      "         [-2.5001e-03,  2.5388e-02,  1.0754e-03,  ..., -5.2219e-03,\n",
      "           3.1846e-04, -4.1332e-03],\n",
      "         [ 6.6646e-03, -8.7011e-03,  1.5091e-02,  ..., -3.5544e-02,\n",
      "           3.6801e-02, -9.7589e-03]],\n",
      "\n",
      "        [[ 9.5068e-03,  1.9187e-02,  1.4491e-02,  ...,  1.4679e-02,\n",
      "           1.7407e-03,  1.0855e-02],\n",
      "         [-7.1992e-03, -8.3328e-03, -1.9069e-03,  ...,  2.3505e-03,\n",
      "          -2.6194e-03, -4.8678e-03],\n",
      "         [-7.6397e-03, -4.5472e-03, -1.1340e-03,  ..., -1.0726e-02,\n",
      "           1.7113e-02, -1.5434e-02],\n",
      "         ...,\n",
      "         [ 1.4445e-02, -2.3533e-02, -1.8151e-03,  ..., -5.4692e-03,\n",
      "           2.7313e-04,  4.1405e-03],\n",
      "         [-7.8665e-03,  2.4815e-02,  1.5410e-02,  ...,  7.2449e-03,\n",
      "           3.8807e-03, -2.4780e-03],\n",
      "         [ 1.1679e-02, -9.9839e-03, -3.0807e-03,  ...,  2.1207e-03,\n",
      "          -5.3663e-03, -4.1186e-04]]], device='cuda:7')\n"
     ]
    }
   ],
   "source": [
    "recon_weight = test_module.reconstruct_weight().detach()\n",
    "print(recon_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de0aafa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9.7046e-03, -1.2939e-02,  2.0447e-03,  ...,  7.7820e-03,\n",
       "          -6.7139e-03, -7.2327e-03],\n",
       "         [ 2.7954e-02, -2.1362e-03, -1.5869e-02,  ...,  1.6357e-02,\n",
       "          -1.0681e-03, -6.1417e-04],\n",
       "         [ 2.8320e-02,  2.6489e-02,  1.6602e-02,  ...,  8.6670e-03,\n",
       "           1.6846e-02, -1.6785e-04],\n",
       "         ...,\n",
       "         [ 9.4604e-03, -1.5381e-02,  1.7578e-02,  ...,  2.8687e-02,\n",
       "          -1.7578e-02, -2.7222e-02],\n",
       "         [ 3.2715e-02,  1.8799e-02,  1.2939e-02,  ..., -1.1597e-03,\n",
       "          -1.7929e-03,  8.2016e-04],\n",
       "         [-2.1240e-02, -1.8799e-02, -7.1411e-03,  ...,  1.1902e-02,\n",
       "           2.1515e-03,  1.4771e-02]],\n",
       "\n",
       "        [[-9.6436e-03, -3.9795e-02,  3.9551e-02,  ..., -3.0396e-02,\n",
       "           2.0752e-03,  2.9419e-02],\n",
       "         [-1.6212e-05, -3.2715e-02,  8.3008e-03,  ...,  1.3306e-02,\n",
       "          -1.0254e-02, -1.4893e-02],\n",
       "         [-8.9722e-03,  3.7354e-02,  1.2817e-03,  ...,  1.1902e-02,\n",
       "          -4.2725e-03, -1.9531e-02],\n",
       "         ...,\n",
       "         [-3.6011e-03, -1.2878e-02, -5.6396e-02,  ..., -5.7129e-02,\n",
       "           3.7598e-02, -3.3691e-02],\n",
       "         [-7.7820e-03, -6.1523e-02,  3.0518e-02,  ..., -1.5869e-02,\n",
       "          -1.4709e-02,  2.5482e-03],\n",
       "         [ 1.0010e-02, -1.0376e-02,  9.3994e-03,  ..., -1.9775e-02,\n",
       "          -2.0508e-02,  4.1199e-03]],\n",
       "\n",
       "        [[-6.1340e-03,  1.6479e-03, -1.9775e-02,  ..., -1.3428e-02,\n",
       "          -1.1780e-02, -1.5991e-02],\n",
       "         [-8.1787e-03,  3.2715e-02,  1.2085e-02,  ..., -1.0559e-02,\n",
       "           2.0996e-02,  8.0109e-04],\n",
       "         [ 1.8311e-02,  1.4160e-02,  1.3062e-02,  ..., -2.3315e-02,\n",
       "           1.9287e-02,  3.4904e-04],\n",
       "         ...,\n",
       "         [ 1.9360e-04,  4.4346e-05,  1.0252e-04,  ...,  2.3079e-04,\n",
       "          -1.4305e-04,  1.7548e-04],\n",
       "         [-3.7842e-02, -3.7842e-03,  2.4780e-02,  ..., -1.0437e-02,\n",
       "          -8.6670e-03, -1.7929e-03],\n",
       "         [-1.5869e-02, -2.3193e-02,  1.2684e-04,  ...,  1.0132e-02,\n",
       "           2.2095e-02,  3.5400e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.3428e-03, -3.0212e-03,  9.5825e-03,  ...,  3.2196e-03,\n",
       "           2.8564e-02,  3.1250e-02],\n",
       "         [-1.2817e-02, -2.4536e-02, -1.6846e-02,  ..., -2.1606e-02,\n",
       "           1.7090e-03,  1.7822e-02],\n",
       "         [-3.1250e-02,  1.4648e-02, -2.0447e-03,  ..., -1.1353e-02,\n",
       "           2.1118e-02, -8.0566e-03],\n",
       "         ...,\n",
       "         [-8.4229e-03,  2.7100e-02,  2.0386e-02,  ..., -2.6733e-02,\n",
       "          -1.5945e-03,  5.2734e-02],\n",
       "         [ 3.7354e-02, -6.7444e-03,  1.9043e-02,  ...,  1.8158e-03,\n",
       "           6.9275e-03, -9.6893e-04],\n",
       "         [-5.7678e-03,  3.6133e-02, -2.1729e-02,  ...,  3.1006e-02,\n",
       "           3.3447e-02, -3.4424e-02]],\n",
       "\n",
       "        [[-1.2085e-02,  7.2632e-03,  1.1536e-02,  ..., -6.0425e-03,\n",
       "          -3.5858e-03,  6.5308e-03],\n",
       "         [ 1.1536e-02,  1.8433e-02,  1.8677e-02,  ...,  1.7578e-02,\n",
       "          -1.5503e-02, -2.3315e-02],\n",
       "         [-6.1951e-03, -4.3030e-03, -2.9907e-03,  ..., -4.5471e-03,\n",
       "           1.6479e-02,  7.7820e-03],\n",
       "         ...,\n",
       "         [-2.1362e-02, -2.0752e-02,  1.1719e-02,  ..., -3.8086e-02,\n",
       "           2.5635e-02, -1.6602e-02],\n",
       "         [ 1.5991e-02,  2.6611e-02,  1.3367e-02,  ...,  4.3030e-03,\n",
       "           5.9204e-03, -1.2756e-02],\n",
       "         [-4.9438e-03,  2.1484e-02,  1.1963e-02,  ..., -5.8105e-02,\n",
       "           1.8066e-02, -2.8564e-02]],\n",
       "\n",
       "        [[ 1.5564e-02,  1.6602e-02,  1.6724e-02,  ...,  1.7334e-02,\n",
       "           1.1902e-02, -3.6469e-03],\n",
       "         [-2.1118e-02, -9.3994e-03,  1.8433e-02,  ..., -5.3101e-03,\n",
       "          -2.5879e-02,  8.9111e-03],\n",
       "         [ 2.7084e-04, -7.8125e-03,  5.7068e-03,  ...,  3.2349e-03,\n",
       "           5.0659e-03, -9.4604e-03],\n",
       "         ...,\n",
       "         [ 1.9775e-02, -2.0996e-02, -7.0190e-03,  ..., -3.0670e-03,\n",
       "           6.9885e-03,  2.0020e-02],\n",
       "         [-8.9722e-03,  2.3193e-02,  2.6367e-02,  ...,  8.4839e-03,\n",
       "          -5.9204e-03, -3.9368e-03],\n",
       "         [-2.2217e-02, -1.2207e-02,  1.3489e-02,  ..., -2.1973e-03,\n",
       "          -1.7456e-02, -1.3916e-02]]], device='cuda:7')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module.original_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04dabdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ba838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARMOR_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
